{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUPYTER NOTEBOOK CANT FIND PYSPARK ON ITS OWN SO HAVE TO MAKE SURE IT FINDS IT. ADD THESE LINES ON TOP OF YOUR JUPYTER NOTEBOOK\n",
    "\n",
    "import pyspark as pd\n",
    "import pyspark.pandas as ps\n",
    "\n",
    "import os\n",
    "os.environ[\"PYARROW_IGNORE_TIMEZONE\"] = \"1\"\n",
    "\n",
    "import os\n",
    "java_home = os.environ.get('JAVA_HOME', None)\n",
    "if not java_home:\n",
    "    java_path = '/opt/homebrew/opt/openjdk'\n",
    "    os.environ['JAVA_HOME'] = java_path\n",
    "else:\n",
    "    print(java_home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/16 08:12:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id value\n",
      "0   1     a\n",
      "1   2     b\n",
      "2   3     c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/16 08:12:47 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "# Create a pandas-on-Spark DataFrame\n",
    "df = ps.DataFrame({'id': [1, 2, 3], 'value': ['a', 'b', 'c']})\n",
    "\n",
    "# Perform operations as you would with pandas\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
